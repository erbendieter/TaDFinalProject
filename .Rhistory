conservative_party_df %>% filter(Year == 1945)
boot_flesch_by_year <- pblapply(all_years, function(x){
sub_data <- conservative_party_df %>% filter(Year == x)
output_flesch <- lapply(1:iters, function(i) boot_flesch(sub_data))
return(unlist(output_flesch))
})
View(boot_flesch_by_year)
names(boot_flesch_by_year) <- all_years
View(boot_flesch_by_year)
year_means <- lapply(boot_flesch_by_year, mean) %>% unname() %>% unlist()
year_ses <- lapply(boot_flesch_by_year, sd) %>% unname() %>% unlist() # bootstrap standard error = sample standard deviation bootstrap distribution
# Plot results--party
plot_dt <- tibble(Year = all_years, mean = year_means, ses = year_ses)
View(plot_dt)
interval1 <- -qnorm((1-0.9)/2)   # 90% multiplier
interval2 <- -qnorm((1-0.95)/2)  # 95% multiplier
# ggplot point estimate + variance
ggplot(plot_dt, aes(colour = Year)) +
geom_linerange(aes(x = Year, ymin = mean - ses*interval1, ymax = mean + ses*interval1), lwd = 1, position = position_dodge(width = 1/2)) +
geom_pointrange(aes(x = Year, y = mean, ymin = mean - ses*interval2, ymax = mean + ses*interval2), lwd = 1/2, position = position_dodge(width = 1/2), shape = 21, fill = "WHITE") +
coord_flip() + theme_bw() + scale_y_continuous(breaks=seq(floor(min(plot_dt$mean)), ceiling(max(plot_dt$mean)), by = 2)) +
xlab("") + ylab("Mean Fleisch Score by Year") + theme(legend.position = "none")
# mean Flesch statistic per party
flesch_point <- irbudgets_df$texts %>% textstat_readability(measure = "Flesch") %>% group_by(irbudgets_df$party) %>% summarise(mean_flesch = mean(Flesch)) %>% setNames(c("party", "mean")) %>% arrange(party)
View(flesch_point)
flesch_point <- conservative_party_df$texts %>% textstat_readability(measure = "Flesch") %>% group_by(conservative_party_df$Year) %>% summarise(mean_flesch = mean(Flesch)) %>% setNames(c("year", "mean")) %>% arrange(Year)
flesch_point <- conservative_party_df$texts %>% textstat_readability(measure = "Flesch") %>% group_by(conservative_party_df$Year) %>% summarise(mean_flesch = mean(Flesch)) %>% setNames(c("year", "mean")) %>% arrange(year)
View(flesch_point)
flesch_point <- conservative_party_df$texts %>% textstat_readability(measure = "Flesch") %>% group_by(conservative_party_df$Year) %>% summarise(mean_flesch = mean(Flesch)) %>% setNames(c("year", "mean_observed")) %>% arrange(year)
View(flesch_point)
str(flesch_point)
flesch_point$mean_boot <- year_means
View(flesch_point)
flesch_point <- conservative_party_df$texts %>% textstat_readability(measure = "Flesch") %>% group_by(conservative_party_df$Year) %>% summarise(mean_flesch = mean(Flesch)) %>% setNames(c("year", "mean_observed")) %>% arrange(year)
View(flesch_point)
flesch_point <- conservative_party_df$texts %>% textstat_readability(measure = "Flesch") %>% group_by(conservative_party_df$Year) %>% summarise(mean_flesch = mean(Flesch)) %>% setNames(c("year", "mean_observed")) %>% arrange(year)
View(flesch_point)
flesch_point$mean_boot <- year_means
View(flesch_point)
View(boot_flesch_by_year)
View(flesch_point)
flesch_point
# 4.1 FRE (https://en.wikipedia.org/wiki/Flesch–Kincaid_readability_tests)
textstat_readability(conservative_party_df, groups = "year"), "Flesch")
# 4.1 FRE (https://en.wikipedia.org/wiki/Flesch–Kincaid_readability_tests)
textstat_readability(texts(data_corpus_irishbudgets, groups = "year"), "Flesch")
textstat_readability(texts(data_corpus_irishbudgets, groups = "year"), "Flesch")
textstat_readability(conservative_party_df$texts, groups = "Year"), "Flesch")
# 4.1 FRE (https://en.wikipedia.org/wiki/Flesch–Kincaid_readability_tests)
flesch_point <- conservative_party_df$texts %>% textstat_readability(measure = "Flesch") %>% group_by(conservative_party_df$Year) %>% summarise(mean_flesch = mean(Flesch)) %>% setNames(c("year", "mean_observed")) %>% arrange(year)
View(flesch_point)
# 4.2 Dale-Chall measure (https://en.wikipedia.org/wiki/Dale–Chall_readability_formula)
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall.old") %>% group_by(conservative_party_df$Year) %>% summarise(mean_flesch = mean(Flesch)) %>% setNames(c("year", "mean_observed")) %>% arrange(year)
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall.old") %>% group_by(conservative_party_df$Year)
View(dale_point)
View(dale_point)
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall.old") %>% group_by(conservative_party_df$Year) %>% summarise(mean_dale = mean(Dale.Chall.old)) %>% setNames(c("year", "mean_observed")) %>% arrange(year)
View(dale_point)
all_readability_measures <- textstat_readability(data_corpus_irishbudgets, c("Flesch", "Dale.Chall", "SMOG", "Coleman.Liau", "Fucks"))
readability_matrix <- cbind(all_readability_measures$Flesch, all_readability_measures$Dale.Chall, all_readability_measures$SMOG, all_readability_measures$Coleman.Liau, all_readability_measures$Fucks)
readability_cor <- cor(readability_matrix)
View(readability_cor)
rownames(readability_cor) <- c("Flesch", "Dale-Chall", "SMOG", "Coleman Liau", "Fucks")
colnames(readability_cor) <- c("Flesch", "Dale-Chall", "SMOG", "Coleman Liau", "Fucks")
readability_cor
all_readability_measures$Flesch
View(dale_point)
# 4.1 FRE (https://en.wikipedia.org/wiki/Flesch–Kincaid_readability_tests)
flesch_point <- conservative_party_df$texts %>% textstat_readability(measure = "Flesch") %>% group_by(conservative_party_df$Year) %>% summarise(mean_flesch = mean(Flesch)) %>% setNames(c("year", "mean")) %>% arrange(year)
# 4.2 Dale-Chall measure (https://en.wikipedia.org/wiki/Dale–Chall_readability_formula)
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall.old") %>% group_by(conservative_party_df$Year) %>% summarise(mean_dale = mean(Dale.Chall.old)) %>% setNames(c("year", "mean")) %>% arrange(year)
View(dale_point)
dale_point$mean
readability_matrix <- cbind(flesch_point$mean,dale_point$mean)
View(readability_matrix)
readability_cor <- cor(readability_matrix)
View(readability_cor)
rownames(readability_cor) <- c("Flesch", "Dale-Chall")
colnames(readability_cor) <- c("Flesch", "Dale-Chall")
readability_cor
all_readability_measures <- textstat_readability(data_corpus_irishbudgets, c("Flesch", "Dale.Chall", "SMOG", "Coleman.Liau", "Fucks"))
readability_matrix <- cbind(all_readability_measures$Flesch, all_readability_measures$Dale.Chall, all_readability_measures$SMOG, all_readability_measures$Coleman.Liau, all_readability_measures$Fucks)
readability_cor <- cor(readability_matrix)
rownames(readability_cor) <- c("Flesch", "Dale-Chall", "SMOG", "Coleman Liau", "Fucks")
colnames(readability_cor) <- c("Flesch", "Dale-Chall", "SMOG", "Coleman Liau", "Fucks")
readability_cor
readability_matrix <- cbind(flesch_point$mean,dale_point$mean)
readability_cor <- cor(readability_matrix)
rownames(readability_cor) <- c("Flesch", "Dale-Chall")
colnames(readability_cor) <- c("Flesch", "Dale-Chall")
readability_cor
# 4.2 Dale-Chall measure (https://en.wikipedia.org/wiki/Dale–Chall_readability_formula)
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale-Chall") %>% group_by(conservative_party_df$Year) %>% summarise(mean_dale = mean(Dale.Chall.old)) %>% setNames(c("year", "mean")) %>% arrange(year)
# 4.2 Dale-Chall measure (https://en.wikipedia.org/wiki/Dale–Chall_readability_formula)
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall.old") %>% group_by(conservative_party_df$Year) %>% summarise(mean_dale = mean(Dale.Chall.old)) %>% setNames(c("year", "mean")) %>% arrange(year)
View(dale_point)
readability_matrix <- cbind(flesch_point$mean,dale_point$mean)
View(readability_matrix)
View(dale_point)
View(readability_matrix)
View(dale_point)
View(flesch_point)
# 4.1 FRE (https://en.wikipedia.org/wiki/Flesch–Kincaid_readability_tests)
flesch_point <- conservative_party_df$texts %>% textstat_readability(measure = "Flesch") %>% group_by(conservative_party_df$Year) %>% summarise(mean_flesch = mean(Flesch)) %>% setNames(c("year", "mean")) %>% arrange(year)
# 4.1 FRE (https://en.wikipedia.org/wiki/Flesch–Kincaid_readability_tests)
flesch_point <- conservative_party_df$texts %>% textstat_readability(measure = "Flesch") %>% group_by(conservative_party_df$Year) %>% summarise(mean_flesch = mean(Flesch)) %>% setNames(c("year", "mean")) %>% arrange(year)
# 4.2 Dale-Chall measure (https://en.wikipedia.org/wiki/Dale–Chall_readability_formula)
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall.old") %>% group_by(conservative_party_df$Year) %>% summarise(mean_dale = mean(Dale.Chall.old)) %>% setNames(c("year", "mean")) %>% arrange(year)
readability_matrix <- cbind(flesch_point$mean,dale_point$mean)
readability_cor <- cor(readability_matrix)
rownames(readability_cor) <- c("Flesch", "Dale-Chall")
colnames(readability_cor) <- c("Flesch", "Dale-Chall")
readability_cor
all_readability_measures <- textstat_readability(data_corpus_irishbudgets, c("Flesch", "Dale.Chall", "SMOG", "Coleman.Liau", "Fucks"))
readability_matrix <- cbind(all_readability_measures$Flesch, all_readability_measures$Dale.Chall, all_readability_measures$SMOG, all_readability_measures$Coleman.Liau, all_readability_measures$Fucks)
readability_cor <- cor(readability_matrix)
rownames(readability_cor) <- c("Flesch", "Dale-Chall", "SMOG", "Coleman Liau", "Fucks")
colnames(readability_cor) <- c("Flesch", "Dale-Chall", "SMOG", "Coleman Liau", "Fucks")
readability_cor
data_corpus_irishbudgets
conservative_party_df
View(all_readability_measures)
all_readability_measures2 <- textstat_readability(data_corpus_ukmanifestos, c("Flesch", "Dale.Chall", "SMOG", "Coleman.Liau", "Fucks"))
View(all_readability_measures2)
View(dale_point)
View(flesch_point)
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall.old")
View(dale_point)
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall.old")
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall.")
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall")
View(dale_point)
# 4.1 FRE (https://en.wikipedia.org/wiki/Flesch–Kincaid_readability_tests)
flesch_point <- conservative_party_df$texts %>% textstat_readability(measure = "Flesch") %>% group_by(conservative_party_df$Year) %>% summarise(mean_flesch = mean(Flesch)) %>% setNames(c("year", "mean")) %>% arrange(year)
# 4.2 Dale-Chall measure (https://en.wikipedia.org/wiki/Dale–Chall_readability_formula)
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall") %>% group_by(conservative_party_df$Year) %>% summarise(mean_dale = mean(Dale.Chall.old)) %>% setNames(c("year", "mean")) %>% arrange(year)
# 4.2 Dale-Chall measure (https://en.wikipedia.org/wiki/Dale–Chall_readability_formula)
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall") %>% group_by(conservative_party_df$Year) %>% summarise(mean_dale = mean(Dale.Chall)) %>% setNames(c("year", "mean")) %>% arrange(year)
readability_matrix <- cbind(flesch_point$mean,dale_point$mean)
readability_cor <- cor(readability_matrix)
rownames(readability_cor) <- c("Flesch", "Dale-Chall")
readability_cor
View(dale_point)
# 4.1 FRE (https://en.wikipedia.org/wiki/Flesch–Kincaid_readability_tests)
flesch_point <- conservative_party_df$texts %>% textstat_readability(measure = "Flesch") %>% group_by(conservative_party_df$Year) %>% summarise(mean_flesch = mean(Flesch)) %>% setNames(c("year", "mean")) %>% arrange(year)
# 4.2 Dale-Chall measure (https://en.wikipedia.org/wiki/Dale–Chall_readability_formula)
# 4.2 Dale-Chall measure (https://en.wikipedia.org/wiki/Dale–Chall_readability_formula)
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = ("Dale.Chall") %>% group_by(conservative_party_df$Year) %>% summarise(mean_dale = mean(Dale.Chall) %>% setNames(c("year", "mean")) %>% arrange(year)
)
esc
# 4.2 Dale-Chall measure (https://en.wikipedia.org/wiki/Dale–Chall_readability_formula)
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall") %>% group_by(conservative_party_df$Year) %>% summarise(mean_dale = mean(Dale.Chall) %>% setNames(c("year", "mean")) %>% arrange(year)
esc
dale_point <- conservative_party_df$texts %>% textstat_readability(measure = "Dale.Chall") %>% group_by(conservative_party_df$Year) %>% summarise(mean_flesch = mean(Dale.Chall)) %>% setNames(c("year", "mean")) %>% arrange(year)
corr_fle <- cbind(flesch_point$mean,dale_point$mean)
readability_matrix <- cbind(flesch_point$mean,dale_point$mean)
readability_cor <- cor(readability_matrix)
rownames(readability_cor) <- c("Flesch", "Dale-Chall")
colnames(readability_cor) <- c("Flesch", "Dale-Chall")
readability_cor
all_readability_measures2$Dale.Chall$
all_readability_measures2$Dale.Chall$mean
all_readability_measures2$Dale.Chall
corr_fle <- cbind(flesch_pointall_readability_measures2$Flesch)
corr_fle <- cbind(flesch_point$mean,all_readability_measures2$Flesch)
all_readability_measures2$Flesch
flesch_point$mean
View(conservative_party_df)
all_readability_measures3 <- textstat_readability(conservative_party, c("Flesch", "Dale.Chall", "SMOG", "Coleman.Liau", "Fucks"))
all_readability_measures3 <- textstat_readability(conservative_party_df, c("Flesch", "Dale.Chall", "SMOG", "Coleman.Liau", "Fucks"))
data_corpus_ukmanifestos
View(data_corpus_ukmanifestos)
[manifestos$Party == 'Con',]
manifestos$Party == 'Con'
all_readability_measures2$Flesch
all_readability_measures2$Flesch[manifestos$Party == 'Con']
corr_fle <- cbind(flesch_point$mean,all_readability_measures2$Flesch[manifestos$Party == 'Con'])
corr_dale <- cbind(dale_point$mean,all_readability_measures2$Dale.Chall[manifestos$Party == 'Con'])
readability_cor <- cor(corr_fle)
rownames(readability_cor) <- c("Fleschsm", "Fleschal")
colnames(readability_cor) <- c("Fleschsm", "Fleschal")
readability_cor
corr_dale <- cbind(dale_point$mean,all_readability_measures2$Dale.Chall[manifestos$Party == 'Con'])
readability_cor <- cor(corr_dale)
rownames(readability_cor) <- c("Fleschsm", "Fleschal")
colnames(readability_cor) <- c("Fleschsm", "Fleschal")
readability_cor
readability_matrix <- cbind(all_readability_measures2$Flesch[manifestos$Party == 'Con'],all_readability_measures2$Dale.Chall[manifestos$Party == 'Con'])
readability_cor <- cor(readability_matrix)
rownames(readability_cor) <- c("Flesch", "Dale-Chall")
colnames(readability_cor) <- c("Flesch", "Dale-Chall")
readability_cor
readability_matrix <- cbind(flesch_point$mean,dale_point$mean)
readability_cor <- cor(readability_matrix)
rownames(readability_cor) <- c("Flesch", "Dale-Chall")
colnames(readability_cor) <- c("Flesch", "Dale-Chall")
readability_cor
# Obtaining the Conservative Party's Manifestos
data("data_corpus_ukmanifestos")
manifestos <- data_corpus_ukmanifestos$documents
c(kwic_church_sawyer$pre,kwic_church_sawyer$post)[1:20]
vocab_custom <- stylest_select_vocab(texts$Text, texts$Author, filter = filter, smooth = 1, nfold = 10, cutoff_pcts = c(25, 50, 75, 99))
filter <- corpus::text_filter(map_case = TRUE, drop_punct = TRUE, drop_symbol = TRUE, drop = stopwords())
set.seed(2000L)
library(stringi)
texts$Text[6] <- stri_encode(texts$Text[6], "", "UTF-8") # I had to encode these for them to work properly
snippetData
library("sophistication")
inaug_speeches <- data_corpus_inaugural # Getting the corpus
snippetData <- snippets_make(inaug_speeches, nsentence = 1, minchar = 150, maxchar = 350)
# Creating snippets of 150-350
snippetData <- snippets_clean(snippetData) # Cleaning snippets
head(snippetData,n=10) # Printing top 10
head(snippetData$text,n=10) # Printing top 10
select(gold_questions, text1,text2)
testData <- sample_n(snippetData, 1000) # Sampling 1000 snippets
snippetPairsMST <- pairs_regular_make(testData) # Min spanning tree pairs
gold_questions <- pairs_gold_make(snippetPairsMST, n.pairs = 10)
select(gold_questions, text1,text2)
select(gold_questions, text1,text2, easier_gold)
select(easier_gold)
select(gold_questions, text1,text2, easier_gold)
select(gold_questions, easier_gold)
select(gold_questions, text1,text2)
View(gold_questions)
tokens <- tokens(texts, remove_punct = TRUE)
Tee <- sum(lengths(tokens))
texts_dfm <- dfm(texts, remove=stopwords("english"),remove_punct = TRUE)
M <- nfeat(texts_dfm)
k <- 44
# Now, I create a sequence of values of b ranging from .4 to .6, incrementing by .01
poss_b <- seq(0.4,.6,.01)
for(b in poss_b){
print(c(i,(k * (Tee)^b)))
}
for(b in poss_b){
print(c(b,(k * (Tee)^b)))
}
unlink('Desktop/School/Text as Data/HW 1_cache', recursive = TRUE)
unlink('Desktop/School/Text as Data/HW_1_cache', recursive = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(quanteda)
library(dplyr)
library(koRpus)
library(koRpus.lang.en)
library(quanteda)
library(dplyr)
inaug_speeches <- data_corpus_inaugural$documents
RR81 <- inaug_speeches['1981-Reagan',]$texts
RR85 <- inaug_speeches['1985-Reagan',]$texts
MTLD(RR81)
MTLD
?MTLD
MTLD(RR81,force.lang = en)
MTLD(RR81,force.lang = en)
MTLD(RR81,force.lang = 'en')
mtld_81 <- MTLD(RR81,force.lang = 'en')
MTLD(RR81,force.lang = 'en')
View(mtld_81)
mtld_81
mtld_85 <- MTLD(RR85,force.lang = 'en',factor.size = 0.72)
mtld_85
splits81 < -split(RR81, ceiling(seq_along(RR81)/20))
splits81 <- split(RR81, ceiling(seq_along(RR81)/20))
View(splits81)
split(RR81, ceiling(seq_along(RR81)/20))
splits81
text_split(RR81,size=20)
library(corpus)
text_split(RR81,size=20)
r20<-text_split(RR81,size=20)
r20<-text_split(RR81,units = "sentences",size=20)
r20<-text_split(RR81,units = "sentences",size=2)
View(r20)
r20<-text_split(RR81,units = "sentences",size=1)
len(RR81)
length(RR81)
r20<-text_split(RR81,units = "sentences",size=5)
View(r20)
r20[1]
r20[2]
View(r20)
r20$text
r20$text[1]
r20<-text_split(RR81,units = "sentences",size=5)
rr85_split<-text_split(RR85,units = "sentences",size=5)
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(quanteda)
library(quanteda)
library(quanteda.corpora)
library(dplyr)
data("data_corpus_immigrationnews")
# Subset of the data
subset_immig <- corpus_subset(data_corpus_immigrationnews, paperName == "guardian" | paperName == "telegraph"|paperName == "ft"|paperName == "times"|paperName == "sun")
# Table of the sources and frequencies of the subset
t = table(subset_immig$documents$paperName)
t
load("custom_stopwords.RData")
# Check below punctuation and numbers. Not working currently
subs_dfm <- dfm(subset_immig,tolower=TRUE,stem=TRUE,removePunct = TRUE,removeNumbers=TRUE,remove = custom_stopwords)
# Trimming dfm
subs_dfm <- dfm_trim(subs_dfm, min_termfreq = 30, min_docfreq = 20)
cat("The remaining number of features is:", nfeat(subs_dfm))
cat("The remaining number of documents is:", ndoc(subs_dfm))
# Check below punctuation and numbers. Not working currently
subs_dfm <- dfm(subset_immig,tolower=TRUE,stem=TRUE,removePunct = TRUE,remove_numbers=TRUE,remove = custom_stopwords)
# Check below punctuation and numbers. Not working currently
subs_dfm <- dfm(subset_immig,tolower=TRUE,stem=TRUE,remove_punct = TRUE,remove_numbers=TRUE,remove = custom_stopwords)
# Trimming dfm
subs_dfm <- dfm_trim(subs_dfm, min_termfreq = 30, min_docfreq = 20)
cat("The remaining number of features is:", nfeat(subs_dfm))
cat("The remaining number of documents is:", ndoc(subs_dfm))
# Set number of topics
k <- 30
# Fit the topic model with the chosen k
top_mod <- LDA(blm_dfm, k = k, method = "Gibbs",  control = list(seed = 1234))
install.packages("topicmodels")
library('topicmodels')
top_mod <- LDA(blm_dfm, k = k, method = "Gibbs",  control = list(seed = 1234))
?`LDAcontrol-class`
# Fit the topic model with the chosen k
top_mod <- LDA(subs_dfm, k = k, method = "Gibbs",  control = list(seed = 10012),iter=3000)
top
top_mod
top_mod@loglikelihood
cat('The log likelihood of my topic model object is:',top_mod@loglikelihood)
knitr::opts_chunk$set(echo = TRUE)
library(quanteda)
library(quanteda.corpora)
library(dplyr)
data("data_corpus_immigrationnews")
# Subset of the data
subset_immig <- corpus_subset(data_corpus_immigrationnews, paperName == "guardian" | paperName == "telegraph"|paperName == "ft"|paperName == "times"|paperName == "sun")
# Table of the sources and frequencies of the subset
t = table(subset_immig$documents$paperName)
t
load("custom_stopwords.RData")
subs_dfm <- dfm(subset_immig,tolower=TRUE,stem=TRUE,remove_punct = TRUE,remove_numbers=TRUE,remove = custom_stopwords)
subs_dfm <- dfm(subset_immig,tolower=TRUE,stem=TRUE,remove_punct = TRUE,remove_numbers=TRUE,remove = custom_stopwords)
# Trimming dfm
subs_dfm <- dfm_trim(subs_dfm, min_termfreq = 30, min_docfreq = 20)
cat("The remaining number of features is:", nfeat(subs_dfm))
cat("The remaining number of documents is:", ndoc(subs_dfm))
library('topicmodels')
# Set number of topics
k <- 30
# Fit the topic model with the chosen k
top_mod <- LDA(subs_dfm, k = k, method = "Gibbs",  control = list(seed = 10012),iter=3000)
top_mod.get_terms()
get_terms(top_mod)
terms <- get_terms(lda, 10)
terms <- get_terms(top_mod, 10)
terms
topics(# Wed Apr 24 20:29:37 2019 ------------------------------
)
topics(top_mod)
like_doc <- topics(top_mod)
top_n(top_mod)
top_n(top_mod,10)
chapter_topics <- tidy(top_mod, matrix = "beta")
library(tidyverse)
install.packages('tidyverse')
library(tidyverse)
chapter_topics <- tidy(top_mod, matrix = "beta")
library(tidytext)
chapter_topics <- tidy(top_mod, matrix = "beta")
View(chapter_topics)
top_n(chapter_topics, 10)
top_terms <- like_doc %>%
group_by(topic)
View(terms)
top_terms <- top_mod %>%
group_by(topic)
topic_tidy <- tidy(top_mod)
topic_tidy
top_terms <- topic_tidy %>%
group_by(term) %>%
top_n(5, beta)
top_terms
top_terms <- topic_tidy %>%
group_by(term) %>%
top_n(1, beta)
top_terms
top_terms <- topic_tidy %>%
group_by(term) %>%
top_n(1, beta) %>%
count()
top_terms
top_terms <- topic_tidy %>%
group_by(term) %>%
top_n(1, beta)
top_terms
top_terms <- topic_tidy %>%
group_by(term) %>%
top_n(1, beta) %>%
count(topic)
top_terms
like_doc
top_topics <- like_doc  %>%
tally()
n_distinct(like_doc)
summarise(n_distinct(like_doc))
View(topic_tidy)
summarise(like_doc)
table(like_doc)
like_doc
topic_tidy <- tidy(top_mod)
View(topic_tidy)
top_terms <- topic_tidy %>%
group_by(term) %>%
top_n(1, beta) %>%
count(topic)
top_terms
term_freqs <- table(like_doc)
max(term_freqs)
sort(term_freqs)
term_freqs
term_freqs <- sort(table(like_doc))
term_freqs
term_freqs[0]
term_freqs[1]
term_freqs[5]
term_freqs[-1]
term_freqs[25:30]
term_freqs[25:31]
term_freqs[26:30]
ranked_topics <- sort(table(like_doc))
top_5_topics <- ranked_topics[26:30]
topic_tidy <- tidy(top_mod)
topic_tidy
topic_tidy <- tidy(top_mod,'beta')
topic_tidy
like_doc
terms
top_5_topics
colnames(top_5_topics)
matrix(top_5_topics)
colnames(top_5_topics)
top_5_topics
as.data.frame.matrix(top_5_topics)
as.data.frame(top_5_topics)
top_5_topics <- as.data.frame(ranked_topics[26:30])
View(top_5_topics)
colnames(top_5_topics)
top_5_topics[1,]
top_5_topics[,1]
print(top_5_topics[,1])
print('The top 5 topics on frequency are')
print(top_5_topics[,1])
terms
terms[30]
terms[.30]
terms[,30]
print
print(top_5_topics[,1])
# Fit the topic model with the chosen k
top_mod <- LDA(subs_dfm, k = k, method = "Gibbs",  control = list(seed = 10012),iter=3000)
kkk
l
stop
terms <- get_terms(top_mod, 10)
like_doc <- topics(top_mod)
topic_tidy <- tidy(top_mod,'beta')
ranked_topics <- sort(table(like_doc))
top_5_topics <- as.data.frame(ranked_topics[26:30])
print('The top 5 topics on frequency are')
print(top_5_topics[,1])
# Most Common
terms[,30]
# Most Common
terms[,30]
# 2nd Most Common
terms[,28]
# 3rd Most Common
terms[,12]
# 4th Most Common
terms[,2]
# 5th Most Common
terms[,15]
relief <- read.csv('a854756.csv', stringsAsFactors=F)
setwd("~/Documents/GitHub/TaDFinalProject")
relief <- read.csv('a854756.csv', stringsAsFactors=F)
View(relief)
relief <- subset(relief, relevance>4)
View(relief)
relief <- subset(relief, relevance==5)
View(relief)
relief <- subset(relief, relevance==4)
relief <- subset(relief, relevance>4)
relief <- subset(relief, relevance>4)
relief <- read.csv('a854756.csv', stringsAsFactors=F)
relief <- subset(relief, relevance>4)
View(relief)
relief <- subset(relief, relevance==5)
View(relief)
cat('The log likelihood of my topic model object is:',top_mod@loglikelihood)
terms
first
# Most Common
t1 <- terms[,30]
# 2nd Most Common
t2 <- terms[,28]
# 3rd Most Common
t3 <- terms[,12]
# 4th Most Common
t4 <- terms[,2]
# 5th Most Common
t5 <- terms[,15]
t1
t2
terms
